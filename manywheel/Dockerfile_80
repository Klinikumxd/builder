FROM nvidia/cuda:8.0-devel-centos6

# MKL
RUN mkdir -p /opt/intel/lib
COPY mkl_libs/libmkl_core.a /opt/intel/lib/libmkl_core.a
COPY mkl_libs/libmkl_gnu_thread.a /opt/intel/lib/libmkl_gnu_thread.a
COPY mkl_libs/libmkl_intel_lp64.a /opt/intel/lib/libmkl_intel_lp64.a

RUN yum install -y git wget curl util-linux xz perl


ENV LC_ALL en_US.UTF-8
ENV LANG en_US.UTF-8
ENV LANGUAGE en_US.UTF-8

# get devtoolset-2
RUN yum install -y yum-utils
RUN yum install -y centos-release-scl
RUN yum-config-manager --enable rhel-server-rhscl-7-rpms
RUN wget http://people.centos.org/tru/devtools-2/devtools-2.repo -O /etc/yum.repos.d/devtools-2.repo
RUN yum install -y devtoolset-2-gcc
RUN yum install -y devtoolset-2-gcc-c++
RUN yum install -y devtoolset-2-gcc-gfortran
RUN yum install -y devtoolset-2-binutils
ENV PATH=/opt/rh/devtoolset-2/root/usr/bin:$PATH
ENV LD_LIBRARY_PATH=/opt/rh/devtoolset-2/root/usr/lib64:/opt/rh/devtoolset-2/root/usr/lib:$LD_LIBRARY_PATH

# cmake
RUN yum install -y cmake

# build python
COPY build_scripts /build_scripts
RUN bash build_scripts/build.sh && rm -r build_scripts

ENV SSL_CERT_FILE=/opt/_internal/certs.pem

# remove unncessary python versions
RUN rm -rf /opt/python/cp26-cp26m /opt/_internal/cpython-2.6.9-ucs2
RUN rm -rf /opt/python/cp26-cp26mu /opt/_internal/cpython-2.6.9-ucs4
RUN rm -rf /opt/python/cp33-cp33m /opt/_internal/cpython-3.3.6
RUN rm -rf /opt/python/cp34-cp34m /opt/_internal/cpython-3.4.6

# get latest cuda patch
RUN wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/patches/2/cuda_8.0.61.2_linux-run && \
    chmod +x cuda_8.0.61.2_linux-run && \
    cp /usr/local/cuda/version.txt /tmp/ && \
    ./cuda_8.0.61.2_linux-run --silent --accept-eula --installdir=/tmp && \
    yes | cp -P /tmp/lib64/* /usr/local/cuda/lib64/

# cuDNN license: https://developer.nvidia.com/cudnn/license_agreement
RUN curl -fsSL http://developer.download.nvidia.com/compute/redist/cudnn/v7.0.5/cudnn-8.0-linux-x64-v7.tgz -O && \
    tar --no-same-owner -xzf cudnn-8.0-linux-x64-v7.tgz -C /usr/local && \
    rm cudnn-8.0-linux-x64-v7.tgz && \
    ldconfig

# NCCL2
RUN wget https://s3.amazonaws.com/pytorch/nccl_2.1.4-1%2Bcuda8.0_x86_64.txz && \
    ls && \
    ls -alh nccl_2.1.4-1+cuda8.0_x86_64.txz && \
    tar --no-same-owner -xvf nccl_2.1.4-1+cuda8.0_x86_64.txz && \
    mv nccl_2.1.4-1+cuda8.0_x86_64/include/* /usr/local/cuda/include/ && \
    cp -P nccl_2.1.4-1+cuda8.0_x86_64/lib/libnccl* /usr/local/cuda/lib64/ && \
    rm -rf nccl_2.1.4-1+cuda8.0_x86_64* && \
    ldconfig

# magma
RUN wget http://icl.cs.utk.edu/projectsfiles/magma/downloads/magma-2.3.0.tar.gz && \
    tar -xvf magma-2.3.0.tar.gz && \
    cd magma-2.3.0 && \
    wget https://raw.githubusercontent.com/pytorch/builder/master/conda/magma-cuda80-2.3.0/cmakelists.patch && \
    wget https://raw.githubusercontent.com/pytorch/builder/master/conda/magma-cuda80-2.3.0/thread_queue.patch && \
    wget https://raw.githubusercontent.com/pytorch/builder/master/conda/magma-cuda80-2.3.0/magma_cparict_tools.patch && \
    wget https://raw.githubusercontent.com/pytorch/builder/master/conda/magma-cuda80-2.3.0/magma_dparict_tools.patch && \
    wget https://raw.githubusercontent.com/pytorch/builder/master/conda/magma-cuda80-2.3.0/magma_sparict_tools.patch && \
    wget https://raw.githubusercontent.com/pytorch/builder/master/conda/magma-cuda80-2.3.0/magma_zparict_tools.patch && \
    patch <cmakelists.patch && \
    patch -p0 <thread_queue.patch && \
    patch -p0 <magma_cparict_tools.patch && \
    patch -p0 <magma_dparict_tools.patch && \
    patch -p0 <magma_sparict_tools.patch && \
    patch -p0 <magma_zparict_tools.patch && \
    mkdir build && \
    cd build && \
    cmake .. -DUSE_FORTRAN=OFF -DGPU_TARGET="All" -DCMAKE_INSTALL_PREFIX=$PREFIX && \
    make -j$(getconf _NPROCESSORS_CONF) && \
    make install && \
    cd ..

RUN rm -f /usr/local/bin/patchelf
RUN git clone https://github.com/NixOS/patchelf && \
    cd patchelf && \
    sed -i 's/serial/parallel/g' configure.ac && \
    ./bootstrap.sh && \
    ./configure && \
    make && \
    make install && \
    cd .. && \
    rm -rf patchelf
